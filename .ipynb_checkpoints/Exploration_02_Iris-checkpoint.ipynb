{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATION 02_IRIS\n",
    "\n",
    "#### 데이터를 다양한 모델로 학습시키고, 각 모델을 평가해보자.\n",
    "###### 사이킷런에서 제공하는 데이터를 활용하여 다양한 머신러닝 모델을 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이 노드의 루브릭\n",
    "\n",
    "   1. 3가지 데이터셋의 구성이 합리적으로 진행되었는가? -> \"feature과 label 선정을 위한 데이터 분석과정이 체계적으로 전개됨\"\n",
    "   2. 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가? -> \"모델 학습 및 테스트가 정상적으로 수행되었음\"\n",
    "   3. 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가? -> \"평가지표 선택 및 이유 설명이 타당함\"\n",
    "   \n",
    "### 이 루브릭을 바탕으로, 실습을 진행해 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 첫번째 실습, 1) load_digits : 손글씨를 분류해 봅시다.\n",
    "\n",
    "  #### 1-1. 데이터를 분석하기 위해 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "데이터셋 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "#데이터셋을 불러온다.\n",
    "digits = load_digits()\n",
    "\n",
    "digits_data = digits.data\n",
    "print(digits.keys())\n",
    "print(\"데이터셋 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 위의 출력 결과를 살펴보면, 우리가 불러온 데이터에는 데이터, 타겟, 프레임, 피쳐 네임, 타겟 네임, 이미지, DESCR 의 카테고리가 있음을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 공식 가이드 문서를 살펴보며 digits 데이터에 대해 알아보자.\n",
    "  \n",
    "  ![손글씨 데이터](./PostingPic/디짓데이터번치.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "\n",
      " 출력해 본 결과, feature data가 될 digits.image 는 8X8 로 저장된 손글씨 데이터 픽셀값임을 추측할 수 있다.\n"
     ]
    }
   ],
   "source": [
    "# Feature Data 확인하기\n",
    "\n",
    "digits_images = digits.images\n",
    "\n",
    "print(digits_images[0])\n",
    "print(\"\\n 출력해 본 결과, feature data가 될 digits.image 는 8X8 로 저장된 손글씨 데이터 픽셀값임을 추측할 수 있다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "\n",
      " 분류할 손글씨 종류에 따라, 위와 같은 라벨이 붙여지게 된다.\n"
     ]
    }
   ],
   "source": [
    "# Label Data 지정하기\n",
    "digits_label = digits.target\n",
    "\n",
    "print(digits_label)\n",
    "print(\"\\n 분류할 손글씨 종류에 따라, 위와 같은 라벨이 붙여지게 된다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 네임즈 :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Target Names 출력하기\n",
    "digits_targetNames = digits.target_names\n",
    "print(\"타겟 네임즈 : \", digits_targetNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pixel_0_0 pixel_0_1 pixel_0_2 pixel_0_3 pixel_0_4 pixel_0_5 pixel_0_6  \\\n",
       "0          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1793       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1794       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1795       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1796       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "     pixel_0_7 pixel_1_0 pixel_1_1  ... pixel_6_7 pixel_7_0 pixel_7_1  \\\n",
       "0          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "3          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "4          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1792       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1793       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1794       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1795       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1796       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "     pixel_7_2 pixel_7_3 pixel_7_4 pixel_7_5 pixel_7_6 pixel_7_7 labels  \n",
       "0          NaN       NaN       NaN       NaN       NaN       NaN      0  \n",
       "1          NaN       NaN       NaN       NaN       NaN       NaN      1  \n",
       "2          NaN       NaN       NaN       NaN       NaN       NaN      2  \n",
       "3          NaN       NaN       NaN       NaN       NaN       NaN      3  \n",
       "4          NaN       NaN       NaN       NaN       NaN       NaN      4  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "1792       NaN       NaN       NaN       NaN       NaN       NaN      9  \n",
       "1793       NaN       NaN       NaN       NaN       NaN       NaN      0  \n",
       "1794       NaN       NaN       NaN       NaN       NaN       NaN      8  \n",
       "1795       NaN       NaN       NaN       NaN       NaN       NaN      9  \n",
       "1796       NaN       NaN       NaN       NaN       NaN       NaN      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 판다스로 Describe 해본다.\n",
    "import pandas as pd\n",
    "\n",
    "# 판다스를 활용하여 \n",
    "# 데이터 Describe 하기\n",
    "\n",
    "#pandas를 활용하여 dataFrame을 작성한다.\n",
    "digits_data_frame = pd.DataFrame(data=digits, columns=digits.feature_names)\n",
    "digits_data_frame[\"labels\"] = digits.target\n",
    "\n",
    "digits_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 확인해보니, (8*8) 크기의 픽셀 값에 + 라벨링 클래스 값(숫자 몇인지)을 갖는 1797 개의 데이터를 보유하고 있음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) Train 데이터, Test 데이터 분류하기\n",
    "\n",
    "   * 학습과 테스트를 진행하기 위해 1,797개의 데이터를 분류해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(digit_data) :  (1797, 64)\n",
      "len(digit_lable) :  (1797,)\n",
      "\n",
      "X_data 개수 : 1437 X_test 개수 :  360\n",
      "\n",
      " * 출력하여 확인해보니, y_test 라벨도 랜덤으로 잘 분리된 것을 확인할 수 있다.\n",
      "[0 4 9 9 3 1 4 1 5 0 4 9 4 1 5 3 3 8 3 6 9 6 0 6 9 3 2 1 8 1 7 0 4 4 1 5 3\n",
      " 0 5 7 3 9 6 5 5 8 8 1 1 2 4 9 5 6 9 2 1 8 5 3 2 7 9 6 3 7 4 2 0 1 0 2 7 3\n",
      " 5 1 8 7 7 2 0 6 6 4 6 8 3 7 4 1 9 3 5 4 0 3 1 3 3 1 2 8 5 0 1 7 2 1 3 3 7\n",
      " 4 0 2 9 0 4 2 5 6 1 2 6 1 8 6 0 2 6 2 6 1 9 4 8 0 4 0 2 3 4 4 1 7 9 7 2 0\n",
      " 3 7 8 8 3 5 4 3 5 4 9 1 3 8 8 1 1 6 7 3 3 9 9 0 6 1 0 1 0 7 6 1 5 9 0 2 2\n",
      " 8 6 8 3 2 9 2 9 3 0 1 2 7 4 9 9 4 9 3 2 7 2 6 9 8 0 2 6 3 4 2 7 6 6 7 7 6\n",
      " 0 7 6 6 0 7 1 4 4 1 0 9 4 0 4 2 4 6 5 3 8 4 1 3 9 8 3 8 9 4 2 0 4 9 2 3 5\n",
      " 0 8 2 5 4 7 5 5 1 0 2 9 0 7 7 6 2 1 5 4 1 0 5 1 6 5 4 8 7 5 9 0 2 2 3 4 4\n",
      " 8 8 8 5 3 0 7 0 3 0 7 9 8 8 3 3 9 8 2 8 4 7 7 9 1 3 5 8 8 2 2 9 4 6 8 0 6\n",
      " 1 2 7 8 8 9 7 9 0 3 7 2 3 0 7 3 9 9 4 2 1 7 4 4 5 7 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 트레인 데이터와 테스트 데이터를 일정 비율로 분리하기 전에 데이터의 길이가 맞는지 확인한다.\n",
    "print('len(digit_data) : ', digits_data.shape)\n",
    "print('len(digit_lable) : ' , digits_label.shape)\n",
    "\n",
    "#테스트셋을 0.2의 비율로 나눈다. 랜덤 세트는 9로 고정한다.(다른 연구자들과 공유할 때 특정한 랜덤 셋이 필요하기 때문)\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=11)\n",
    "\n",
    "print('\\nX_data 개수 :' , len(x_train), 'X_test 개수 : ' , len(x_test))\n",
    "\n",
    "print('\\n * 출력하여 확인해보니, y_test 라벨도 랜덤으로 잘 분리된 것을 확인할 수 있다.')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) 다양한 모델로 학습시키고, 평가해보기\n",
    "\n",
    "* 준비한 데이터셋을 이용하여, 다양한 딥러닝 모델을 적용시켜 본다.\n",
    "* 학습 후, 모델의 테스트 데이터 예측 결과를 해석하면서 모델의 성능 평가 지표로는 무엇이 좋을지 생각해본다.\n",
    "* sklearn.metrics에서 제공하는 평가지표 중 가장 적절하다고 생각되는 것을 고르고, 이유를 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 의사결정나무(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=77)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#의사결정나무 모델의 적용\n",
    "decision_tree = DecisionTreeClassifier(random_state=77)\n",
    "decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        38\n",
      "           1       0.81      0.78      0.79        37\n",
      "           2       0.94      0.85      0.89        39\n",
      "           3       0.79      0.76      0.77        41\n",
      "           4       0.76      0.85      0.80        41\n",
      "           5       0.87      0.96      0.91        27\n",
      "           6       0.94      0.97      0.95        30\n",
      "           7       0.88      0.81      0.84        36\n",
      "           8       0.78      0.82      0.80        34\n",
      "           9       0.73      0.81      0.77        37\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.85      0.84      0.84       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#sklearn.metrics 패키지에서 제공하는 classification_report를 이용하여 모델의 성능 평가\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=28)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#랜덤포레스트 기법의 적용\n",
    "random_forest = RandomForestClassifier(random_state=77)\n",
    "random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       1.00      0.90      0.95        41\n",
      "           4       0.98      0.98      0.98        41\n",
      "           5       0.93      1.00      0.96        27\n",
      "           6       1.00      0.97      0.98        30\n",
      "           7       0.92      0.97      0.95        36\n",
      "           8       0.92      1.00      0.96        34\n",
      "           9       0.97      0.95      0.96        37\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.metrics 패키지에서 제공하는 classificaton_report를 이용하여 모델의 성능 평가\n",
    "y_predict = random_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) SVM 모델(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#SVM 모델의 적용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       1.00      0.93      0.96        41\n",
      "           4       1.00      1.00      1.00        41\n",
      "           5       0.96      1.00      0.98        27\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       0.95      0.97      0.96        36\n",
      "           8       0.97      1.00      0.99        34\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = svm_model.predict(x_test)\n",
    "\n",
    "#SVM 모델의 평가\n",
    "svm_report = classification_report(y_test, y_predict)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SGD 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#SGD 모델의 적용\n",
    "sgd_model=SGDClassifier()\n",
    "\n",
    "sgd_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.90      1.00      0.95        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       1.00      0.83      0.91        41\n",
      "           4       1.00      0.98      0.99        41\n",
      "           5       0.84      1.00      0.92        27\n",
      "           6       1.00      0.97      0.98        30\n",
      "           7       0.94      0.94      0.94        36\n",
      "           8       0.97      0.91      0.94        34\n",
      "           9       0.90      0.95      0.92        37\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.95       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = sgd_model.predict(x_test)\n",
    "\n",
    "#SGD 모델의 평가\n",
    "sgd_report =classification_report(y_test, y_predict)\n",
    "\n",
    "print(sgd_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=100000)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#로지스틱 회귀 모델의 적용\n",
    "logistic_model = LogisticRegression(max_iter=100000)\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      0.97      0.99        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       1.00      0.95      0.97        41\n",
      "           4       1.00      1.00      1.00        41\n",
      "           5       0.90      1.00      0.95        27\n",
      "           6       1.00      0.97      0.98        30\n",
      "           7       0.97      0.97      0.97        36\n",
      "           8       0.89      0.91      0.90        34\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = logistic_model.predict(x_test)\n",
    "\n",
    "#로지스틱 회귀 모델의 평가\n",
    "\n",
    "logistic_report = classification_report(y_test, y_predict)\n",
    "print(logistic_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. 모델 성능 평가 지표 찾아보기\n",
    "\n",
    "* 위와 같이,    \n",
    " 1. 의사결정나무   \n",
    " 2. 랜덤포레스트    \n",
    " 3. SVM 모델    \n",
    " 4. SGD 분류     \n",
    " 5. 로지스틱 회귀   \n",
    " \n",
    " 모델을 이용하여 학습과 평가를 진행하였고, Classification_report 를 통해 각 모델의 성능 지표를 출력하였다.    \n",
    "\n",
    "\n",
    "* 그럼 이 때, __각각의 모델 별 classification_report 가 의미하는 수치는 무엇일까? (주목할 수치는 무엇인가?)__\n",
    "\n",
    "* 그리고 __digits 식별 데이터에는 어떤 성능 평가 지표가 가장 유효할까?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝으로 손글씨 digits 분류를 수행할 때, 어떤 성능 평가 지표가 가장 의미있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 우리는 이번 노드를 통해 정확도(Acurracy)이외에도 recall(재현율), Precision(정밀도), F1 Score같은 평가 지표들을 알아보았다.   \n",
    " * 손글씨를 분류하는 딥러닝 모델을 설계할 때, 어떤 성능 평가 지표로 측정하면 가장 의미있는 모델 평가가 이루어질까?\n",
    " \n",
    " * 우선 손글씨 분류 모델의 경우, 캐주얼한 목적으로도 사용 가능하지만, 보안이나 개인정보와 관련된 중요한 목적으로도 사용될 수 있을 것이다.\n",
    " \n",
    "   > - 따라서, 손글씨 분류에 가장 적합할 것이라고 생각되는 성능 평가 지표는 __F1 Score 이다.__    \n",
    "   \n",
    " * 물론, 노드를 통해 배운 Precision(각 개별 분류 과정이 얼마나 잘 진행되었는가), Recall(예측된 결과를 신뢰할 수 있겠는가)과 같은   \n",
    "   지표들도 중요하지만, 손글씨 분류는 목적이 다양하여    \n",
    "   \n",
    "   1. 개별 분류가 잘 수행되었는가(Precision)\n",
    "   2. 분류 결과가 신뢰할 만 한가(Recall)\n",
    "   \n",
    "   의 모든 목적을 만족하는 것이 안전하다고 판단되기 때문이다.    \n",
    "  \n",
    "  * F1 Score의 경우 Precision과 Recall의 조화 평균이므로, 이 두가지를 모두 고려할 수 있다고 결론지었다.\n",
    "  \n",
    "  \n",
    "  ___\n",
    "  * 그럼 이 예상에 따라, 각 딥러닝 모델의 학습 결과를 확인하고 가장 효율적인 모델을 추측해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) 의사결정나무\n",
    "\n",
    "![의사결정나무](./PostingPic/손글씨_의사결정나무.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결과에 따르면, 의사결정나무 방법의 정확도는 0.84이며 각 클래스간의 편차는 다소 큰 편이다.(precision의 경우 0.7~1.0까지)     \n",
    "   * 우리가 주목해야 할 F1 스코어의 경우 0.84의 정확도를 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 랜덤 포레스트\n",
    "\n",
    "![랜덤포레스트](./PostingPic/손글씨_랜덤포레스트.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결과를 확인하면, 정확도는 0.97로 의사결정나무보다 확연히 나아진 결과를 보여준다!(또한, 클래스 간의 차이도 미미하다)    \n",
    "   * 우리가 주목해야 할 F1 스코어 또한 0.97로 높은 수준을 보이며, 정밀도, 재현율, F1 스코어 모두에서 고득점을 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) SVM(Support Vector Machine)\n",
    "\n",
    "![서포트 벡터 머신](./PostingPic/손글씨_SVM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 확인해보면, 정확도는 0.99로 매우 높다! 클래스 간의 편차도 0.3 이내로 미미하다.    \n",
    "   * 정밀도, 재현율, F1 score 모두 0.99로 동일하고, 지금까지의 모델 중 가장 높은 수치를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SGD 방식\n",
    "\n",
    "![SGD 방식](./PostingPic/손글씨_SGD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결과에서, SGD 방식은 0.96의 정확도를 보인다. 다만 클래스간의 편차는 랜덤 포레스트나 SVM에 비해 다소 큰 모습을 보인다.    \n",
    "   * 주목해야 할 F1 Score는 0.96으로 높은 편이며, 다른 수치와의 차이도 크지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 로지스틱 회귀 방식\n",
    "\n",
    "![로지스틱회귀](./PostingPic/손글씨_로지스틱회귀.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 로지스틱 회귀 모델의 경우, 정확도는 0.97로 높은 편이며, 클래스 간 차이는 좀 큰 편이다.(1.0정도)\n",
    "   * F1 스코어는 0.98로 높은 편이며, 정밀도나 재현율과의 차이도 크지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손글씨 데이터를 분류하실 때는 ~아무거나~ 는 아니고 SVM 모델을 추천드립니다.\n",
    "\n",
    "   * 거의 모든 모델이 0.95 이상의 높은 정확도와 F1 Score 수치를 보여주는 것을 확인할 수 있다.(2번,3번 실습에 비하면 매우 높은 수치)  \n",
    "   * 그래도 굳이 하나를 고르라면, 안정적으로 가장 높은 수치가 나온 SVM 모델이 가장 적합하지 않을까 싶다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두번째 실습, 와인을 분류해봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1) 데이터 분류를 위해 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 와인 데이터를 사이킷런에서 로드해온다.\n",
    "wine = load_wine()\n",
    "\n",
    "# 와인 데이터를 변수에 저장한 뒤, 데이터 형태를 확인해본다.\n",
    "wine_data = wine.data\n",
    "print(wine_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 와인.data의 형태를 확인해보니 (178, 13)의 형태로 이루어진 데이터임을 알 수 있다. (총 178개의 쌍, 13개의 데이터 유형)\n",
    "   * 공식 가이드 문서를 통해 와인.data 안의 데이터 유형을 확인해보자.\n",
    "   \n",
    "   ![winde 데이터](./PostingPic/와인데이터.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 13개의 데이터 유형은 각각    \n",
    "   알코올 도수, Malic acid(사과산), Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids,    \n",
    "   Nonflavanoid phenols, Proanthocyanins, Colot intensity, Hue, OD280/OD315 of diluted wines, Proline 이다.    \n",
    "   \n",
    "   \n",
    "   * 이 데이터 이외에 다른 리턴 값들을 살펴보자.\n",
    "   ![와인데이터 번치](./PostingPic/와인데이터번치.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류할 라벨들을 출력하여 확인해보자 : \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Lable Data 지정하기(각각의 분류에서 '정답' 이 될 label 데이터를 wine_label 이라는 변수에 넣었다.)\n",
    "wine_label = wine.target\n",
    "\n",
    "print(\"분류할 라벨들을 출력하여 확인해보자 : \")\n",
    "print(wine_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  labels  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 판다스를 활용하여 \n",
    "# 데이터 Describe 하기\n",
    "\n",
    "#pandas를 활용하여 dataFrame을 작성한다.\n",
    "wine_data_frame = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
    "wine_data_frame[\"labels\"] = wine.target\n",
    "\n",
    "wine_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 총 13개의 와인별 특성에 1개의 라벨데이터(타겟)을 적용하여, 178개 X 14특성 의 데이터 쌍을 출력해 보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 train, test 데이터 분리하기\n",
    "   * 학습을 진행할 train 데이터와 학습 결과를 테스트할 test 데이터를 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(wine_data) :  (178, 13)\n",
      "len(wine_lable) :  (178,)\n",
      "\n",
      "X_data 개수 : 142 X_test 개수 :  36\n",
      "\n",
      " * 출력하여 확인해보니, y_test 라벨도 랜덤으로 잘 분리된 것을 확인할 수 있다.\n",
      "[0 0 0 2 0 0 2 2 2 1 2 0 2 1 1 0 1 1 0 0 0 0 0 0 0 2 1 1 0 1 0 1 1 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 트레인 데이터와 테스트 데이터를 일정 비율로 분리하기 전에 데이터의 길이가 맞는지 확인한다.\n",
    "print('len(wine_data) : ', wine_data.shape)\n",
    "print('len(wine_lable) : ' , wine_label.shape)\n",
    "\n",
    "#테스트셋을 0.2의 비율로 나눈다. 랜덤 세트는 9로 고정한다.(다른 연구자들과 공유할 때 특정한 랜덤 셋이 필요하기 때문)\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=9)\n",
    "\n",
    "print('\\nX_data 개수 :' , len(x_train), 'X_test 개수 : ' , len(x_test))\n",
    "\n",
    "print('\\n * 출력하여 확인해보니, y_test 라벨도 랜덤으로 잘 분리된 것을 확인할 수 있다.')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 다양한 모델로 학습시키고, 평가해 보기\n",
    "\n",
    "* 준비한 데이터셋을 이용하여, 다양한 딥러닝 모델을 적용시켜 본다.\n",
    "* 학습 후, 모델의 테스트 데이터 예측 결과를 해석하면서 모델의 성능 평가 지표로는 무엇이 좋을지 생각해본다.\n",
    "* sklearn.metrics에서 제공하는 평가지표 중 가장 적절하다고 생각되는 것을 고르고, 이유를 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 총 5개의 모델을 적용하여 확인해본다. 의사결정나무, 랜덤포레스트, SVM, SGD, 로지스틱 회귀\n",
    "\n",
    "#### 2-3-1. 의사결정나무(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=28)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#의사결정나무 모델의 적용\n",
    "decision_tree = DecisionTreeClassifier(random_state=28)\n",
    "decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#sklearn.metrics 패키지에서 제공하는 classification_report를 이용하여 모델의 성능 평가\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-2. 랜덤포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=28)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#랜덤포레스트 기법의 적용\n",
    "random_forest = RandomForestClassifier(random_state=28)\n",
    "random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.metrics 패키지에서 제공하는 classificaton_report를 이용하여 모델의 성능 평가\n",
    "y_predict = random_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-3. SVM 모델(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#SVM 모델의 적용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        17\n",
      "           1       0.67      0.73      0.70        11\n",
      "           2       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.68      0.68      0.68        36\n",
      "weighted avg       0.74      0.75      0.75        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = svm_model.predict(x_test)\n",
    "\n",
    "#SVM 모델의 평가\n",
    "svm_report = classification_report(y_test, y_predict)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-4. SGD모델 (stochastic Gradient Descent Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#SGD 모델의 적용\n",
    "sgd_model=SGDClassifier()\n",
    "\n",
    "sgd_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86        17\n",
      "           1       1.00      0.55      0.71        11\n",
      "           2       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.77      0.70      0.71        36\n",
      "weighted avg       0.79      0.75      0.75        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD 모델의 평기\n",
    "y_predict = sgd_model.predict(x_test)\n",
    "sgd_report =classification_report(y_test, y_predict)\n",
    "\n",
    "print(sgd_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3-5. 로지스틱 회귀 모델(logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#로지스틱 회귀 모델의 적용\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델의 평가\n",
    "y_predict = logistic_model.predict(x_test)\n",
    "logistic_report = classification_report(y_test, y_predict)\n",
    "\n",
    "print(logistic_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. 모델 성능 평가 지표 찾아보기\n",
    "\n",
    "* 위와 같이,    \n",
    " 1. 의사결정나무   \n",
    " 2. 랜덤포레스트    \n",
    " 3. SVM 모델    \n",
    " 4. SGD 분류     \n",
    " 5. 로지스틱 회귀   \n",
    " \n",
    " 모델을 이용하여 학습과 평가를 진행하였고, Classification_report 를 통해 각 모델의 성능 지표를 출력하였다.    \n",
    "\n",
    "\n",
    "* 그럼 이 때, __각각의 모델 별 classification_report 가 의미하는 수치는 무엇일까? (주목할 수치는 무엇인가?)__\n",
    "\n",
    "* 그리고 __Wine 분류 데이터에는 어떤 성능 평가 지표가 가장 유효할까?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[여기도 참고해보자](https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html)\n",
    "\n",
    "[Classification_Report가 의미하는 것들](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __WINE 데이터 분류에서는 어떤 성능 평가 지표가 가장 의미있을까?__\n",
    "\n",
    "   * 우리는 이번 노드를 통해 정확도(Acurracy)이외에도 recall(재현율), Precision(정밀도), F1 Score같은 평가 지표들을 알아보았다.   \n",
    "   * 그렇다면 와인 데이터 분류에서는 어떤 성능 평가 지표가 가장 의미있을까?\n",
    "   - 일단 정확도를 제외한 재현율, 정밀도, F1스코어 중 하나를 골라야 한다는 가정 아래 생각해보면,    \n",
    "   - 와인을 분류하는 경우 일반적으로는 '이 예측 전체가 얼마나 신뢰할 수 있니' 보다는 '각각의 와인 분류가 알맞게 수행되었니?' 에 좀 더 촛점이 맞춰지는 경우가 많다. ex)스팸메일 케이스처럼.\n",
    "   \n",
    "   > - 따라서, 와인 데이터를 분류할 때는 __Precision(정밀도)가 중요하다.__    \n",
    "   \n",
    "   > 따라서 아래의 각 모델 평가 결과를 볼 때, __정밀도와 F1스코어, 정확도가 높은 순__ 으로 가장 유효한 모델을 골라볼 수 있겠다.\n",
    "   \n",
    "   \"실제로 분류했을 때 이 와인이 (0번/1번/2번) 와인이니 아니니?\" 가 더 중요하다고 생각되기 때문이다.    \n",
    "   (0번 와인을 마시고 싶었지만 잘못된 분류로 2번 와인을 마셨다고 해서 죽지는 않는다! 기분은.. 안좋을수도 있겠지만...?)   \n",
    "   \n",
    "   \n",
    "   - 물론, 만약을 가정하여 생산한 와인 중 \"1번 와인에서 발암물질이 검출되었고, 그래서 와인을 분류해 전량 리콜하고 싶은 상황이라면\"   \n",
    "   \n",
    "     이 머신러닝 모델이 개별 와인을 0, 1, 2번으로 잘 구분했는지 아닌지 보다는   \n",
    "     \n",
    "     이미 분류한 예측을 '신뢰할 수 있는지 아닌지' 가 더 중요해질 것이므로 Precision 보다는 recall 이 중요해질 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그럼 각각의 평가결과를 살펴보자.\n",
    "\n",
    "1) 의사결정나무 모델의 결과\n",
    "![의사결정나무결과](./PostingPic/의사결정나무결과.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 가장 간단하게 살펴볼 수 있는 성능 지표인 '정확도' 에서, 의사결정 나무는 0.97 값을 기록했다.\n",
    "   \n",
    "   다만 0,1,2의 각 클래스(3종류의 와인)에 대해서 모두 일관적인 정확도를 보이는 것은 아니고, 의외로 샘플의 수(support)가 가장 적었던 2-> 샘플 수가 가장 많았던 1-> 0 의 순으로 정확도가 높았다.     \n",
    "   \n",
    "   \n",
    "   * 우리가 중요하게 볼 precision의 average는 0.97로 비교적 높은 값을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 랜덤포레스트 모델의 결과\n",
    "\n",
    "![랜덤포레스트 결과](./PostingPic/랜덤포레스트결과.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 랜덤 포레스트 모델의 정확도는 1.00으로, 가장 높은 값이 나왔다.(너무 높아 오류일까 싶어서 다른 랜덤 셋으로 돌렸지만 결과가 동일했다)\n",
    "   \n",
    "   이 경우 신기하게도 0,1,2 세 클래스에 대해 모두 일관적인 정확도를 보였으며, 평균(macro, weight) 에서도 일관적으로 높은 결과값을 보였다.           \n",
    "   \n",
    "   \n",
    "    \n",
    "   * 우리가 주목하는 precision(정밀도), F1 스코어, 정확도 모두 높게 나온 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) SVM 모델의 결과\n",
    "\n",
    "![SVM모델](./PostingPic/svm결과.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * SVM 모델의 경우, 정확도가 0.75로 매우 낮은 편이며 각 클래스간의 격차도 큰 편이다. (0.94 ~ 0.4)     \n",
    "   * 우리가 주목하는 정밀도, f1스코어, 정확도 모두 0.6~0.75 수준으로 비교적 낮게 측정되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) SGD 방법의 결과\n",
    "![SGD결과](./PostingPic/와인_sgd모델평가.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * SGD 방식의 경우, 정확도가 0.75로 낮은 편이며 각 클래스 간의 격차는 SVM보다는 작았지만 적지 않게 있었다. (0.56~0.86)  \n",
    "   * 주목하는 정밀도, f1스코어, 정확도 모두 0.7n 선에서 비슷하게 유지되는 편이었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) 로지스틱 회귀 모델\n",
    "![로지스틱회귀결과](./PostingPic/와인_로지스틱모델평가.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 로지스틱 회귀 모델의 경우, 정확도가 1.0으로 매우 높았다. 클래스 간의 격차도 없었다.\n",
    "   * 주목하는 정밀도, f1스코어, 정확도 모두 높게 나왔고, Random Forest와 유사했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 와인 데이터를 분류할 때는 Random Forest, 로지스틱 회귀를 쓰세요\n",
    "\n",
    "   * 결과적으로, 가장 정밀도와 정확도, F1 스코어가 높아 두루두루 높은 점수를 얻은 것은 Random Forest, 로지스틱 회귀 방식이었다.     \n",
    "   \n",
    "     랜덤 포레스트와 유사한 의사결정나무도 높은 점수를 보여 신뢰할 만 했다.     \n",
    "    \n",
    "   * 랜덤포레스트, 로지스틱 회귀 > 의사결정나무 > SGD > SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 번외\n",
    "   이건 번외지만, 로지스틱 회귀를 실행하는 도중에 오류가 발생하여 이를 해결할 수 있는 방법을 서칭해보았다.\n",
    "   \n",
    "   ![로지스틱회귀 오류](./PostingPic/로지스틱회귀오류.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오류 로그 중 'iterations reched limit' 라는 부분을 검색해보니, 반복하는 회수가 넘어가면 생기는 오류라고 해서\n",
    "    \n",
    "   > logistic_model = LogisticRegression(max_iter=100000)\n",
    "   \n",
    "라고 횟수를 제한하니 오류 없이 수행되었다. 다만 처음 횟수를 10000으로 제한했을 때 정확도가 너무 낮게 나와 혹시 횟수제한 때문인가? 하고 횟수를 100000으로 10배 높여주었는데, 똑같은 정확도를 보여 '그냥 이 데이터 분류 방법에는 안 맞는구나' 하게 되었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세 번째 실습, 유방암 여부를 진단해봅시다!\n",
    "\n",
    "3-1. 데이터 분류를 위해 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#유방암 데이터를 가져옴.\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "#가져온 유방암 데이터의 모양을 확인해보자.\n",
    "cancer_data = cancer.data\n",
    "print(cancer_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 가져온 데이터를 확인했을 때, 유방암 데이터는 각각 30개의 특징을 가진 569개의 데이터로 이루어져 있음을 확인할 수 있다.\n",
    "     공식 가이드 문서를 통해 다른 요소들도 함께 확인해보자.\n",
    "     \n",
    "    ![유방암데이터가이드](./PostingPic/유방암데이터번치.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# 30개의 피쳐도, feature_names를 출력하여 확인해보자.\n",
    "cancer_featureNames = cancer.feature_names\n",
    "print(cancer_featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "\n",
      " ** 음성인지, 양성인지를 알아보는 데이터이므로 라벨이 0/1의 2가지로 이루어졌음을 알 수 있다.\n",
      "\n",
      " 타겟 네임즈를 출력하면 : \n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# 이제 양성인지, 음성인지를 판단할 라벨을 넣어주고 확인해보자.\n",
    "cancer_label = cancer.target\n",
    "print(len(cancer_label))\n",
    "print(cancer_label)\n",
    "\n",
    "print(\"\\n ** 음성인지, 양성인지를 알아보는 데이터이므로 라벨이 0/1의 2가지로 이루어졌음을 알 수 있다.\")\n",
    "\n",
    "# target_names도 출력해보자\n",
    "cancer_target_names = cancer.target_names\n",
    "print(\"\\n 타겟 네임즈를 출력하면 : \")\n",
    "print(cancer_target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  labels  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 판다스를 활용하여 \n",
    "# 데이터 Describe 하기\n",
    "\n",
    "#pandas를 활용하여 dataFrame을 작성한다.\n",
    "cancer_data_frame = pd.DataFrame(data=cancer_data, columns=cancer.feature_names)\n",
    "cancer_data_frame[\"labels\"] = cancer.target\n",
    "\n",
    "cancer_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 데이터를 출력하면 30개의 특징과 1개의 클래스(양성/음성 유무)를 가진, 569개의 데이터쌍임을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 학습 데이터와 테스트 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(cancer_data) :  (569, 30)\n",
      "len(cancer_lable) :  (569,)\n",
      "\n",
      "X_data 개수 : 455 X_test 개수 :  114\n",
      "\n",
      " * 출력하여 확인해보니, y_test 라벨도 랜덤으로 잘 분리된 것을 확인할 수 있다.\n",
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1\n",
      " 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 트레인 데이터와 테스트 데이터를 일정 비율로 분리하기 전에 데이터의 길이가 맞는지 확인한다.\n",
    "print('len(cancer_data) : ', cancer_data.shape)\n",
    "print('len(cancer_lable) : ' , cancer_label.shape)\n",
    "\n",
    "#테스트셋을 0.2의 비율로 나눈다. 랜덤 세트는 9로 고정한다.(다른 연구자들과 공유할 때 특정한 랜덤 셋이 필요하기 때문)\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer_data, cancer_label, test_size=0.2, random_state=8)\n",
    "\n",
    "print('\\nX_data 개수 :' , len(x_train), 'X_test 개수 : ' , len(x_test))\n",
    "\n",
    "print('\\n * 출력하여 확인해보니, y_test 라벨도 랜덤으로 잘 분리된 것을 확인할 수 있다.')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3 다양한 모델을 학습시키고, 평가해보기\n",
    "\n",
    "   * 5개의 모델을 적용하여 학습시키고, 학습 결과에 대해 평가해본다.\n",
    "   * 이전의 실습 내용과 같은 순서로\n",
    "   1. 의사결정나무   \n",
    "   \n",
    "   2. 랜덤포레스트    \n",
    "   \n",
    "   3. SVM     \n",
    "   \n",
    "   4. SGD     \n",
    "   \n",
    "   5. 로지스틱 회귀\n",
    "   \n",
    "   순으로 시행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 의사결정나무(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 길이 :  455 테스트 데이터 길이 :  114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#의사결정나무 모델 적용\n",
    "decision_tree = DecisionTreeClassifier(random_state=39)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "print(\"학습데이터 길이 : \", len(x_train), \"테스트 데이터 길이 : \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        46\n",
      "           1       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#sklearn.metrics 패키지에서 제공하는 classification_report를 이용하여 모델의 성능 평가\n",
    "y_predict = decision_tree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=39)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#랜덤포레스트 기법 적용\n",
    "random_forest = RandomForestClassifier(random_state=39)\n",
    "random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        46\n",
      "           1       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.metrics 패키지에서 제공하는 classificaton_report를 이용하여 모델의 성능 평가\n",
    "y_predict = random_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) SVM모델(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#SVM 모델의 적용\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92        46\n",
      "           1       0.92      0.99      0.95        68\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = svm_model.predict(x_test)\n",
    "\n",
    "#SVM 모델의 평가\n",
    "svm_report = classification_report(y_test, y_predict)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) SGD 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#SGD 모델의 적용\n",
    "sgd_model=SGDClassifier()\n",
    "\n",
    "sgd_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        46\n",
      "           1       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD 모델의 평기\n",
    "y_predict = sgd_model.predict(x_test)\n",
    "sgd_report =classification_report(y_test, y_predict)\n",
    "\n",
    "print(sgd_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=100000)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#로지스틱 회귀 모델의 적용\n",
    "logistic_model = LogisticRegression(max_iter=100000)\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        46\n",
      "           1       0.97      0.97      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 모델의 평가\n",
    "y_predict = logistic_model.predict(x_test)\n",
    "logistic_report = classification_report(y_test, y_predict)\n",
    "\n",
    "print(logistic_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. 모델 평가 성능 지표 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 5가지 모델을 이용하여 학습과 평가를 진행하였고, Classification_report 를 통해 각 모델의 성능 지표를 출력하였다.    \n",
    "\n",
    "\n",
    "* 그럼 이 때, __각각의 모델 별 classification_report 의 수치를 분석하면 어떨까? (주목할 수치는 무엇인가?)__\n",
    "\n",
    "* 그리고 __유방암 판별 데이터에는 어떤 성능 평가 지표가 가장 유효할까?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유방암 데이터 판별에서는 어떤 성능 평가 지표가 가장 중요할까?     \n",
    "\n",
    "   * 우리가 살펴본 다양한 평가지표 중, 주목해볼만한 지표는     \n",
    "    __정확도, Precision(정밀도), Recall(재현율), F1 스코어__ 의 5가지였다. \n",
    "    \n",
    "   * 유방암 데이터 판별에 대한 딥러닝 모델의 성능 평가 지표를 살펴볼 때, 어떤 요소를 유의미하게 가져가야 하는가?\n",
    " \n",
    "   * 유방암 판단과 같은 케이스는 '예측의 신뢰도' 가 중요한 사안이다.\n",
    "     LMS 실습에서 설명된 내용처럼, 암 검사 결과에 대해 통보받은 환자 집단이 있을 때,   \n",
    "     개별 환자에게 의미있는 것은 '각 환자가 암인가 아닌가' 보다 '이 예측이 신뢰있게 수행되어 내가 받은 예측(양성, 음성)이 진짜인가'   \n",
    "     의 여부이다. \n",
    "    \n",
    "   * 따라서, 유방암 판별 모델의 성가를 평가할 지표로는 __Recall(재현율)__ 이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그럼 이러한 판단을 바탕으로, 각 학습 모델의 결과를 확인해보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 의사결정나무\n",
    "\n",
    "![의사결정나무](./PostingPic/유방암_의사결정나무.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결과를 확인해보면, 정확도는 0.93으로 비교적 높은 편이며 클래스간의 편차도 크지 않은 것으로 보인다.\n",
    "   * 다만, 우리가 주목해야 할 recall의 경우 클래스의 편차가 다소 있으며 (약 0.1정도), 그럼에도 불구하고 recall값은 0.93 수준이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 랜덤포레스트\n",
    "\n",
    "![랜덤포레스트결과](./PostingPic/유방암_랜덤포레스트.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 랜덤포레스트 모델의 정확도는 0.95 점으로, 의사결정나무보다 소량 증가하였다. 전반적으로도 확률들이 더 높다.\n",
    "   * 우리가 주목할 recall에 대해서도, 클래스 간 편차가 의사결정나무보다 줄어들었다.(0.06수준)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) SVM 모델\n",
    "\n",
    "![svm결과](./PostingPic/유방암_svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결과를 확인하면, 이번에는 SVM이 의사결정 나무, 랜덤 포레스트와 비슷한 수준의 정확도를 보인다는 것을 확인할 수 있다.(0.94)\n",
    "   * 다만 recall및 precision에서 클래스간 편차가 다소 심한 편이다.(recall에서 0.12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) SGD 방식\n",
    "\n",
    "![SGD방식](./PostingPic/유방암_sgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 지금까지의 지표들은 거의 유사한 결과를 보이고 있다. 정확도 0.95.\n",
    "   * 다만, SGD 방식의 recall에서 클래스간의 편차가 가장 작게 나왔으며, 전반적인 확률이 거의 동일하게 나와 안정적인 느낌이 든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) 로지스틱 회귀 방식\n",
    "\n",
    "![로지스틱회귀](./PostingPic/유방암_로지스틱회귀.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이 모델도 유사하지만, 모델 중에서 정확도는 가장 높다. 정확도 0.96.\n",
    "   * 또한 각 클래스 간의 편차가 크지 않고 비교적 안정적인 결과를 보여준다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유방암 진단에는 로지스틱 회귀, SGD 모델은 어떤가요\n",
    "\n",
    "   * 실험한 5종의 모든 모델이 거의 비슷한 수준의 정확도와 recall 수치를 보여서 수치상으로 무엇이 더 적합할 지 판단하기 어려웠다.   \n",
    "   * 그래도 개중에 가장 '괜찮다' 라고 생각될만한 모델을 꼽는다면, 각 클래스들의 편차가 크지 않았던 SGD 모델과 로지스틱 회귀를 꼽고 싶다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
